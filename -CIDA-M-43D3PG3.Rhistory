# JAGS model code for two-component bivariate normal mixture
model_string  <- "
model
{
# Likelihood
for (i in 1:N) {
Z[i] ~  dbern(lambda)
Y[i, 1:2] ~ dmnorm(mu_g[Z[i]+1, 1:2], Sigma_inv[1:2,1:2])
}
# priors on proportion
lambda ~ dbeta(1, 1)
# Priors on sigma
Sigma_inv[1:2,1:2] ~ dwish(R[,], nu)  # Wishart prior for the precision matrix
Sigma[1:2,1:2] <- inverse(Sigma_inv[1:2,1:2])
# Priors on means
mu_g[1, 1:2] ~ dmnorm(mu_prior_1[1:2], cov_mu_prior_1[1:2,1:2])
mu_g[2, 1:2] ~ dmnorm(mu_prior_2[1:2], cov_mu_prior_2[1:2,1:2])
}
"
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations,
mu_prior_1 <- c(0,0),
mu_prior_2 <- c(0,0),
cov_mu_prior_1 <- diag(2)*1000,
cov_mu_prior_1 <- diag(2)*1000,
nu = 3,
R = diag(2)
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
# JAGS model code for two-component bivariate normal mixture
model_string  <- "
model
{
# Likelihood
for (i in 1:N) {
Z[i] ~  dbern(lambda)
Y[i, 1:2] ~ dmnorm(mu_g[Z[i]+1, 1:2], Sigma_inv[1:2,1:2])
}
# priors on proportion
lambda ~ dbeta(1, 1)
# Priors on sigma
Sigma_inv[1:2,1:2] ~ dwish(R[,], nu)  # Wishart prior for the precision matrix
Sigma[1:2,1:2] <- inverse(Sigma_inv[1:2,1:2])
# Priors on means
mu_g[1, 1:2] ~ dmnorm(mu_prior_1[1:2], cov_mu_prior_1[1:2,1:2])
mu_g[2, 1:2] ~ dmnorm(mu_prior_2[1:2], cov_mu_prior_2[1:2,1:2])
}
"
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations,
mu_prior_1 <- c(0,0),
mu_prior_2 <- c(0,0),
cov_mu_prior_1 <- diag(2)*1000,
cov_mu_prior_2 <- diag(2)*1000,
nu = 3,
R = diag(2)
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
cov_mu_prior_2 <- diag(2)*1000
cov_mu_prior_1
cov_mu_prior_2
# JAGS model code for two-component bivariate normal mixture
model_string <- "
model {
# Likelihood
for (i in 1:N) {
z[i] ~ dbern(lambda)  # Latent variable for component assignment
# Shared covariance matrix (Sigma_inv) for both components
Y[i,1:2] ~ dmnorm(mu[z[i] + 1,], Sigma_inv[,])  # Precision matrix used here
}
# Priors
# Mixture proportion (lambda)
lambda ~ dbeta(1, 1)  # Flat prior for mixture proportion
# Priors for the means (each component has different covariance for the prior)
for (j in 1:2) {
mu[j, 1:2] ~ dmnorm(mu_prior[j,], cov_mu_prior[j,,])
}
# Shared precision matrix (inverse of covariance matrix)
Sigma_inv[1:2,1:2] ~ dwish(R[,], nu)  # Wishart prior for the precision matrix
Sigma[1:2,1:2] <- inverse(Sigma_inv[,])  # Covariance matrix is the inverse of precision
}
"
# Prepare the data for JAGS
data_jags <- list(
Y = your_data_matrix,  # Nx2 data matrix
N = nrow(your_data_matrix),  # Number of observations
mu_prior = matrix(c(0, 0, 0, 0), nrow = 2, ncol = 2),  # Means of the prior for mu (2x2)
cov_mu_prior = array(c(diag(2), diag(2) * 2), dim = c(2, 2, 2)),  # Different covariance for the priors of mu
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
# JAGS model code for two-component bivariate normal mixture
model_string <- "
model {
# Likelihood
for (i in 1:N) {
z[i] ~ dbern(lambda)  # Latent variable for component assignment
# Shared covariance matrix (Sigma_inv) for both components
Y[i,1:2] ~ dmnorm(mu[z[i] + 1,], Sigma_inv[,])  # Precision matrix used here
}
# Priors
# Mixture proportion (lambda)
lambda ~ dbeta(1, 1)  # Flat prior for mixture proportion
# Priors for the means (each component has different covariance for the prior)
for (j in 1:2) {
mu[j, 1:2] ~ dmnorm(mu_prior[j,], cov_mu_prior[j,,])
}
# Shared precision matrix (inverse of covariance matrix)
Sigma_inv[1:2,1:2] ~ dwish(R[,], nu)  # Wishart prior for the precision matrix
Sigma[1:2,1:2] <- inverse(Sigma_inv[,])  # Covariance matrix is the inverse of precision
}
"
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0, 0, 0, 0), nrow = 2, ncol = 2),  # Means of the prior for mu (2x2)
cov_mu_prior = array(c(diag(2), diag(2) * 2), dim = c(2, 2, 2)),  # Different covariance for the priors of mu
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
working_directory <- "C:\\Users\\zhushu\\OneDrive\\Graduate File\\Course\\Thesis"
## frequentest
source(paste0(working_directory, '/Code/01_data_cleaning.R'))
LIIA_baseline <- filter(df_liia, visit=="baseline")
data.fit <- LIIA_baseline%>%
select(c('CSF.AB42/40.Ratio', 'Plasma.AB42/40.Ratio'))%>%drop_na()
# JAGS model code for two-component bivariate normal mixture
model_string <- "
model {
# Likelihood
for (i in 1:N) {
z[i] ~ dbern(lambda)  # Latent variable for component assignment
# Shared covariance matrix (Sigma_inv) for both components
Y[i,1:2] ~ dmnorm(mu[z[i] + 1,], Sigma_inv[,])  # Precision matrix used here
}
# Priors
# Mixture proportion (lambda)
lambda ~ dbeta(1, 1)  # Flat prior for mixture proportion
# Priors for the means (each component has different covariance for the prior)
for (j in 1:2) {
mu[j, 1:2] ~ dmnorm(mu_prior[j,], cov_mu_prior[j,,])
}
# Shared precision matrix (inverse of covariance matrix)
Sigma_inv[1:2,1:2] ~ dwish(R[,], nu)  # Wishart prior for the precision matrix
Sigma[1:2,1:2] <- inverse(Sigma_inv[,])  # Covariance matrix is the inverse of precision
}
"
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0, 0, 0, 0), nrow = 2, ncol = 2),  # Means of the prior for mu (2x2)
cov_mu_prior = array(c(diag(2), diag(2) * 2), dim = c(2, 2, 2)),  # Different covariance for the priors of mu
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
c(diag(2), diag(2) * 2)
array(c(diag(2), diag(2) * 2), dim = c(2, 2, 2))
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0, 0, 0, 0), nrow = 2, ncol = 2),  # Means of the prior for mu (2x2)
cov_mu_prior = array(c(diag(2), diag(2) * 2), dim = c(2, 2, 2)),  # Different covariance for the priors of mu
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
?array
array(c(diag(2), diag(2) * 2), dim = c(2, 2, 2))
# JAGS model code for two-component bivariate normal mixture
model_string <- "
model {
# Likelihood
for (i in 1:N) {
z[i] ~ dbern(lambda)  # Latent variable for component assignment
# Shared covariance matrix (Sigma_inv) for both components
Y[i,1:2] ~ dmnorm(mu[z[i] + 1,], Sigma_inv[,])  # Precision matrix used here
}
# Priors
# Mixture proportion (lambda)
lambda ~ dbeta(1, 1)  # Flat prior for mixture proportion
# Priors for the means (each component has different covariance for the prior)
mu[1, 1:2] ~ dmnorm(mu_prior[1,], cov_mu_prior[1,,])
mu[2, 1:2] ~ dmnorm(mu_prior[2,], cov_mu_prior[2,,])
# Shared precision matrix (inverse of covariance matrix)
Sigma_inv[1:2,1:2] ~ dwish(R[,], nu)  # Wishart prior for the precision matrix
Sigma[1:2,1:2] <- inverse(Sigma_inv[,])  # Covariance matrix is the inverse of precision
}
"
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0, 0, 0, 0), nrow = 2, ncol = 2),  # Means of the prior for mu (2x2)
cov_mu_prior = array(c(diag(2), diag(2) * 2), dim = c(2, 2, 2)),  # Different covariance for the priors of mu
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
mu_prior
mu_prior = matrix(c(0, 0, 0, 0), nrow = 2, ncol = 2)
mu_prior[2]
mu_prior[2,]
cov_mu_prior[2,,]
cov_mu_prior = array(c(diag(2), diag(2) * 2), dim = c(2, 2, 2))
cov_mu_prior[2,,]
cov_mu_prior[2,]
cov_mu_prior[2]
# JAGS model code for two-component bivariate normal mixture
model_string <- "
model {
# Likelihood
for (i in 1:N) {
z[i] ~ dbern(lambda)  # Latent variable for component assignment
# Shared covariance matrix (Sigma_inv) for both components
Y[i,1:2] ~ dmnorm(mu[z[i] + 1,], Sigma_inv[,])  # Precision matrix used here
}
# Priors
# Mixture proportion (lambda)
lambda ~ dbeta(1, 1)  # Flat prior for mixture proportion
# Priors for the means (each component has different covariance for the prior)
mu[1, 1:2] ~ dmnorm(mu_prior[1,], cov_mu_prior_1[,])
mu[2, 1:2] ~ dmnorm(mu_prior[2,], cov_mu_prior_2[,])
# Shared precision matrix (inverse of covariance matrix)
Sigma_inv[1:2,1:2] ~ dwish(R[,], nu)  # Wishart prior for the precision matrix
Sigma[1:2,1:2] <- inverse(Sigma_inv[,])  # Covariance matrix is the inverse of precision
}
"
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0, 0, 0, 0), nrow = 2, ncol = 2),  # Means of the prior for mu (2x2)
cov_mu_prior_1 = diag(2),  # Different covariance for the priors of mu
cov_mu_prior_2 = diag(2),
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
# Burn-in period
update(model, 1000)
# Draw samples from posterior
samples <- coda.samples(model, variable.names = c("mu_g", "Sigma", "Z", "lambda"), n.iter = 5000)
# Draw samples from posterior
samples <- coda.samples(model, variable.names = c("mu", "Sigma", "Z", "lambda"), n.iter = 5000)
# JAGS model code for two-component bivariate normal mixture
model_string <- "
model {
# Likelihood
for (i in 1:N) {
Z[i] ~ dbern(lambda)  # Latent variable for component assignment
# Shared covariance matrix (Sigma_inv) for both components
Y[i,1:2] ~ dmnorm(mu[z[i] + 1,], Sigma_inv[,])  # Precision matrix used here
}
# Priors
# Mixture proportion (lambda)
lambda ~ dbeta(1, 1)  # Flat prior for mixture proportion
# Priors for the means (each component has different covariance for the prior)
mu[1, 1:2] ~ dmnorm(mu_prior[1,], cov_mu_prior_1[,])
mu[2, 1:2] ~ dmnorm(mu_prior[2,], cov_mu_prior_2[,])
# Shared precision matrix (inverse of covariance matrix)
Sigma_inv[1:2,1:2] ~ dwish(R[,], nu)  # Wishart prior for the precision matrix
Sigma[1:2,1:2] <- inverse(Sigma_inv[,])  # Covariance matrix is the inverse of precision
}
"
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0, 0, 0, 0), nrow = 2, ncol = 2),  # Means of the prior for mu (2x2)
cov_mu_prior_1 = diag(2),  # Different covariance for the priors of mu
cov_mu_prior_2 = diag(2),
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
# JAGS model code for two-component bivariate normal mixture
model_string <- "
model {
# Likelihood
for (i in 1:N) {
Z[i] ~ dbern(lambda)  # Latent variable for component assignment
# Shared covariance matrix (Sigma_inv) for both components
Y[i,1:2] ~ dmnorm(mu[Z[i] + 1,], Sigma_inv[,])  # Precision matrix used here
}
# Priors
# Mixture proportion (lambda)
lambda ~ dbeta(1, 1)  # Flat prior for mixture proportion
# Priors for the means (each component has different covariance for the prior)
mu[1, 1:2] ~ dmnorm(mu_prior[1,], cov_mu_prior_1[,])
mu[2, 1:2] ~ dmnorm(mu_prior[2,], cov_mu_prior_2[,])
# Shared precision matrix (inverse of covariance matrix)
Sigma_inv[1:2,1:2] ~ dwish(R[,], nu)  # Wishart prior for the precision matrix
Sigma[1:2,1:2] <- inverse(Sigma_inv[,])  # Covariance matrix is the inverse of precision
}
"
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0, 0, 0, 0), nrow = 2, ncol = 2),  # Means of the prior for mu (2x2)
cov_mu_prior_1 = diag(2),  # Different covariance for the priors of mu
cov_mu_prior_2 = diag(2),
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
# Burn-in period
update(model, 1000)
# Draw samples from posterior
samples <- coda.samples(model, variable.names = c("mu", "Sigma", "Z", "lambda"), n.iter = 5000)
# Check summary of posterior distributions
summary(samples)
# Check summary of posterior distributions
summary(samples)[1]
matrix(c(0, 0, 0, 0), nrow = 2, ncol = 2)
model$parameters$mean
working_directory <- "C:\\Users\\zhushu\\OneDrive\\Graduate File\\Course\\Thesis"
## frequentest
source(paste0(working_directory, '/Code/01_data_cleaning.R'))
LIIA_baseline <- filter(df_liia, visit=="baseline")
data.fit <- LIIA_baseline%>%
select(c('CSF.AB42/40.Ratio', 'Plasma.AB42/40.Ratio'))%>%drop_na()
model <- Mclust(data.fit,G = 2)
classification <- model$classification
#plot(model, what = "density", type = "persp")
plot(model, what = 'density')
plot(densityMclust(data.fit), what = "BIC")
plot(model, what = "classification")
plot(model, what = "uncertainty")
summary(model)
model$parameters$pro
model$parameters$mean
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0.01, 0.01, 0.05, 0.08), nrow = 2, ncol = 2),  # Means of the prior for mu (2x2)
cov_mu_prior_1 = diag(2),  # Different covariance for the priors of mu
cov_mu_prior_2 = diag(2),
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
# Burn-in period
update(model, 1000)
# Draw samples from posterior
samples <- coda.samples(model, variable.names = c("mu", "Sigma", "Z", "lambda"), n.iter = 5000)
# Check summary of posterior distributions
summary(samples)[1]
## Bayesian
library(rjags)
# JAGS model code for two-component bivariate normal mixture
model_string <- "
model {
# Likelihood
for (i in 1:N) {
Z[i] ~ dbern(lambda)  # Latent variable for component assignment
# Shared covariance matrix (Sigma_inv) for both components
Y[i,1:2] ~ dmnorm(mu[Z[i] + 1,], Sigma_inv[,])  # Precision matrix used here
}
# Priors
# Mixture proportion (lambda)
lambda ~ dbeta(1, 1)  # Flat prior for mixture proportion
# Priors for the means (each component has different covariance for the prior)
mu[1, 1:2] ~ dmnorm(mu_prior[1,], cov_mu_prior_1[,])
mu[2, 1:2] ~ dmnorm(mu_prior[2,], cov_mu_prior_2[,])
# Shared precision matrix (inverse of covariance matrix)
Sigma_inv[1:2,1:2] ~ dwish(R[,], nu)  # Wishart prior for the precision matrix
Sigma[1:2,1:2] <- inverse(Sigma_inv[,])  # Covariance matrix is the inverse of precision
}
"
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0.01, 0.01, 0.05, 0.08), nrow = 2, ncol = 2),  # Means of the prior for mu (2x2)
cov_mu_prior_1 = diag(2)*10^6,  # Different covariance for the priors of mu
cov_mu_prior_2 = diag(2)*10^6,
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
# Burn-in period
update(model, 1000)
# Draw samples from posterior
samples <- coda.samples(model, variable.names = c("mu", "Sigma", "Z", "lambda"), n.iter = 5000)
# Check summary of posterior distributions
summary(samples)[1]
model$parameters$mean
model
working_directory <- "C:\\Users\\zhushu\\OneDrive\\Graduate File\\Course\\Thesis"
## frequentest
source(paste0(working_directory, '/Code/01_data_cleaning.R'))
LIIA_baseline <- filter(df_liia, visit=="baseline")
data.fit <- LIIA_baseline%>%
select(c('CSF.AB42/40.Ratio', 'Plasma.AB42/40.Ratio'))%>%drop_na()
model_freq <- Mclust(data.fit,G = 2)
classification <- model_freq$classification
#plot(model, what = "density", type = "persp")
plot(model_freq, what = 'density')
plot(densityMclust(data.fit), what = "BIC")
plot(model_freq, what = "classification")
plot(model_freq, what = "uncertainty")
summary(model_freq)
model_freq$parameters$pro
model_freq$parameters$mean
model_freq$parameters$variance$sigma
matrix(c(0.01, 0.01, 0.05, 0.08), nrow = 2, ncol = 2)
mu_prior = matrix(c(0.01, 0.05, 0.01, 0.08), nrow = 2, ncol = 2),
matrix(c(0.01, 0.05, 0.01, 0.08), nrow = 2, ncol = 2)
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0.01, 0.01, 0.05, 0.08), nrow = 2, ncol = 2, byrow = T),  # Means of the prior for mu (2x2)
cov_mu_prior_1 = diag(2)*10^6,  # Different covariance for the priors of mu
cov_mu_prior_2 = diag(2)*10^6,
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0.01, 0.01, 0.05, 0.08), nrow = 2, ncol = 2, byrow = T),  # Means of the prior for mu (2x2)
cov_mu_prior_1 = diag(2)*10^6,  # Different covariance for the priors of mu
cov_mu_prior_2 = diag(2)*10^6,
R = diag(2),  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
# Burn-in period
update(model, 1000)
# Draw samples from posterior
samples <- coda.samples(model, variable.names = c("mu", "Sigma", "Z", "lambda"), n.iter = 5000)
# Check summary of posterior distributions
summary(samples)[1]
## Bayesian
library(rjags)
# JAGS model code for two-component bivariate normal mixture
model_string <- "
model {
# Likelihood
for (i in 1:N) {
Z[i] ~ dbern(lambda)  # Latent variable for component assignment
# Shared covariance matrix (Sigma_inv) for both components
Y[i,1:2] ~ dmnorm(mu[Z[i] + 1,], Sigma_inv[,])  # Precision matrix used here
}
# Priors
# Mixture proportion (lambda)
lambda ~ dbeta(1, 1)  # Flat prior for mixture proportion
# Priors for the means (each component has different covariance for the prior)
mu[1, 1:2] ~ dmnorm(mu_prior[1,], cov_mu_prior_1[,])
mu[2, 1:2] ~ dmnorm(mu_prior[2,], cov_mu_prior_2[,])
# Shared precision matrix (inverse of covariance matrix)
Sigma_inv[1:2,1:2] ~ dwish(R[,], nu)  # Wishart prior for the precision matrix
Sigma[1:2,1:2] <- inverse(Sigma_inv[,])  # Covariance matrix is the inverse of precision
}
"
# Prepare the data for JAGS
data_jags <- list(
Y = data.fit,  # Nx2 data matrix
N = nrow(data.fit),  # Number of observations
mu_prior = matrix(c(0.01, 0.01, 0.05, 0.08), nrow = 2, ncol = 2, byrow = T),  # Means of the prior for mu (2x2)
cov_mu_prior_1 = diag(2)*10^6,  # Different covariance for the priors of mu
cov_mu_prior_2 = diag(2)*10^6,
R = diag(2)*10^6,  # Scale matrix for the Wishart prior for Sigma_inv
nu = 3  # Degrees of freedom for the Wishart prior
)
# Initialize JAGS model
model <- jags.model(textConnection(model_string), data = data_jags, n.chains = 4)
# Burn-in period
update(model, 1000)
# Draw samples from posterior
samples <- coda.samples(model, variable.names = c("mu", "Sigma", "Z", "lambda"), n.iter = 5000)
# Check summary of posterior distributions
summary(samples)[1]
# Check summary of posterior distributions
summary(samples)[2]
traceplot(samples)
par(mfrow = c(4,4))
traceplot(samples)
traceplot(samples[, "mu"])
traceplot(samples[, "mu[1,1"])
traceplot(samples[, "mu[1,1]")
traceplot(samples[, "mu[1,1]"])
par(mfrow = c(4,4))
traceplot(samples[, "mu[1,1]"])
par(mfrow = c(2,2))
traceplot(samples[, "mu[1,1]"])
traceplot(samples[, "mu"])
